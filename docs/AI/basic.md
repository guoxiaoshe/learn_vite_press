训练大型语言模型需要提供大量的文本数据，模型利用这些数据来学习人类语言的结构、语法和语义。

## LLM训练方式
### 机器学习类型
1. 监督学习
2. 无监督学习(不依赖标注数据)
3. 强化学习

### LLM训练与无监督学习
训练过程通常是通过无监督学习完成的，使用一种叫做自我监督学习的技术。在自我监督学习中，模型通过预测序列中的下一个词来标记输入的数据，并给出之前的词，从而生成自己的标签。这种方法使得模型可以在没有明确标注的情况下进行训练，从而大大降低了数据收集和标注的成本。[1](https://juejin.cn/post/7242965902877917245)

### 训练过程
![训练过程](./img/01.awebp)

### GPT框架中的预训练（Pre-Training）
目的：提高模型的泛化能力和通用能力
结果：生成基座模型（Base Model）

### 数据标注
对原始数据进行标记和分类，提供有意义的数据，以用于机器学习训练
目的：使模型更好地理解数据，提高准确率和效率
#### 重要性
1. 解决数据的精准性问题
原始数据存在噪音，非结构化
2. 让机器理解数据

以下是数据标注的解决方案：


自动标注(Automated Annotation)：利用机器学习模型执行初始的数据标注，然后由人工审查以保证数据质量。


主动学习(Active Learning)：机器学习模型建议哪些数据样本需要标注，从而减少所需的人工工作量。


众包(CrowdSourcing)：通过众包平台如Amazon Mechanical Turk，利用标注队伍分配标注任务，减少所需时间

## 参考文献
[【人工智能技术专题】「入门到精通系列教程」零基础带你进军人工智能领域的全流程技术体系和实战指南（LLM、AGI和AIGC都是什么）](https://juejin.cn/post/7242965902877917245)
[NLP、GPT-Pre-Training和数据标注都是什么](https://juejin.cn/post/7243311106685059129)

